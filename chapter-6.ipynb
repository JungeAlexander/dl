{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Deep Learning* - Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/OH3gI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Output activation</b><br>\n",
    "The function applied to the node in the output layer\n",
    "* Binary output (yes/no): Sigmoid\n",
    "* Multi-class output (red, green blue): Softmax\n",
    "* Gaussian output: linear\n",
    "\n",
    "<b>Activation functions</b><br>\n",
    "The function applied to the nodes in the hidden layer. A full list available at https://en.wikipedia.org/wiki/Activation_function\n",
    "Most commonly used: \n",
    "\n",
    "* sigmoid\n",
    "* tanh\n",
    "* Rectified Linear Unit (ReLu)\n",
    "\n",
    "<b>Cost functions</b><br>\n",
    "The optimization goal. Most commonly used:\n",
    "* Mean-Squared error: continous output\n",
    "* Cross-entropy: binary / categorical output\n",
    "\n",
    "<b>Back-propagation</b><br>\n",
    "Update the weights of the neural network with the negative derivative of the error multipled by the learning rate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical\n",
    "\n",
    "This section just shows how to use Keras to learn a neural network the XOR function. [Keras](keras.io) is a high-level neural network API that builds on [TensorFlow](https://www.tensorflow.org/) or [Theano](http://deeplearning.net/software/theano/). Be aware that both TensorFlow and Theano WILL use your GPU if available, so your computer can run quite warm or the battery be quickly drained\n",
    "\n",
    "First off, lets verify that a linear model cannot learn the XOR function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn import linear_model\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Truth table\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a linear model w. predictions\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5],\n",
       "       [ 0.5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should predict everything to be 0.5\n",
    "reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is the Neural Network using the Keras language\n",
    "\n",
    "# Just instantiate a new object\n",
    "model = Sequential() \n",
    "\n",
    "# This is the first hidden layer. There are 2 hidden nodes (+1 bias node). The input dimension is two\n",
    "model.add(Dense(2, input_dim=2, activation='tanh', kernel_initializer='glorot_uniform')) \n",
    "\n",
    "# This is the final output layer. There is one binary output\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# The model will be optimized using Stochastic Gradient Descent, the target is to minimuze the cross entropy\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, y, batch_size=1, epochs=3000, verbose=0)\n",
    "print(model.predict_classes(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
